{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize, Pad\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "from dataset import VOC12,cityscapes\n",
    "from transform import Relabel, ToLabel, Colorize\n",
    "from visualize import Dashboard\n",
    "\n",
    "import importlib\n",
    "from iouEval import iouEval, getColorEntry\n",
    "\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 34 #pascal=22, cityscapes=20\n",
    "\n",
    "color_transform = Colorize(NUM_CLASSES)\n",
    "image_transform = ToPILImage()\n",
    "\n",
    "class Args():\n",
    "    cuda =True  #NOTE: cpu-only has not been tested so you might have to change code if you deactivate this flag\n",
    "    model = \"erfnet\"\n",
    "    state = False\n",
    "    port = 8097\n",
    "    datadir = \"/esat/toyota/trace/deeplearning/datasets_public/cityscapes/leftImg8bit_trainvaltest\"\n",
    "    height=512\n",
    "    num_epochs=5\n",
    "    num_workers=4\n",
    "    batch_size=2\n",
    "    steps_loss=50\n",
    "    steps_plot=50\n",
    "    epochs_save=0    #You can use this value to save model every X epochs\n",
    "    savedir=\"~/Document/thesis_kontras/\"\n",
    "    decoder = False\n",
    "    pretrainedEncoder =False #, default=\"../trained_models/erfnet_encoder_pretrained.pth.tar\")\n",
    "    visualize =False\n",
    "    iouTrain =False #recommended: False (takes more time to train otherwise)\n",
    "    iouVal = True  \n",
    "    resume = False \n",
    "args= Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentations - different function implemented to perform random augments on both image and target\n",
    "class MyCoTransform(object):\n",
    "    def __init__(self, enc, augment=True, height=512):\n",
    "        self.enc=enc\n",
    "        self.augment = augment\n",
    "        self.height = height\n",
    "        pass\n",
    "    def __call__(self, input, target):\n",
    "        # do something to both images\n",
    "        input =  Resize(self.height, Image.BILINEAR)(input)\n",
    "        target = Resize(self.height, Image.NEAREST)(target)\n",
    "\n",
    "        if(self.augment):\n",
    "            # Random hflip\n",
    "            hflip = random.random()\n",
    "            if (hflip < 0.5):\n",
    "                input = input.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                target = target.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            #Random translation 0-2 pixels (fill rest with padding\n",
    "            transX = random.randint(-2, 2) \n",
    "            transY = random.randint(-2, 2)\n",
    "\n",
    "            input = ImageOps.expand(input, border=(transX,transY,0,0), fill=0)\n",
    "            target = ImageOps.expand(target, border=(transX,transY,0,0), fill=255) #pad label filling with 255\n",
    "            input = input.crop((0, 0, input.size[0]-transX, input.size[1]-transY))\n",
    "            target = target.crop((0, 0, target.size[0]-transX, target.size[1]-transY))   \n",
    "\n",
    "        input = ToTensor()(input)\n",
    "        if (self.enc):\n",
    "            target = Resize(int(self.height/8), Image.NEAREST)(target)\n",
    "        target = ToLabel()(target)\n",
    "        target = Relabel(255, 19)(target)\n",
    "\n",
    "        return input, target\n",
    "\n",
    "\n",
    "class CrossEntropyLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.loss = torch.nn.NLLLoss(weight)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        return self.loss(torch.nn.functional.log_softmax(outputs, dim=1), targets)\n",
    "\n",
    "def save_checkpoint(state, is_best, filenameCheckpoint, filenameBest):\n",
    "    torch.save(state, filenameCheckpoint)\n",
    "    if is_best:\n",
    "        print (\"Saving model as best\")\n",
    "        torch.save(state, filenameBest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "savedir = f'../save/{args.savedir}'\n",
    "\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "with open(savedir + '/opts.txt', \"w\") as myfile:\n",
    "    myfile.write(str(args))\n",
    "\n",
    "#Load Model\n",
    "assert os.path.exists(args.model + \".py\"), \"Error: model definition not found\"\n",
    "model_file = importlib.import_module(args.model)\n",
    "model = model_file.Net(NUM_CLASSES)\n",
    "copyfile(args.model + \".py\", savedir + '/' + args.model + \".py\")\n",
    "\n",
    "if args.cuda:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "if args.state:\n",
    "    #if args.state is provided then load this state for training\n",
    "    #Note: this only loads initialized weights. If you want to resume a training use \"--resume\" option!!\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(args.state))\n",
    "    except AssertionError:\n",
    "        model.load_state_dict(torch.load(args.state,\n",
    "            map_location=lambda storage, loc: storage))\n",
    "    #When model is saved as DataParallel it adds a model. to each key. To remove:\n",
    "    #state_dict = {k.partition('model.')[2]: v for k,v in state_dict}\n",
    "    #https://discuss.pytorch.org/t/prefix-parameter-names-in-saved-model-if-trained-by-multi-gpu/494\n",
    "    \"\"\"\n",
    "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict keys are there\n",
    "        own_state = model.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name not in own_state:\n",
    "                 continue\n",
    "            own_state[name].copy_(param)\n",
    "        return model\n",
    "\n",
    "    #print(torch.load(args.state))\n",
    "    model = load_my_state_dict(model, torch.load(args.state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/esat/toyota/trace/deeplearning/datasets_public/cityscapes/leftImg8bit_trainvaltest/leftImg8bit/train\n",
      "/esat/toyota/trace/deeplearning/datasets_public/cityscapes/gtFine_trainvaltest/gtFine/train\n",
      "/esat/toyota/trace/deeplearning/datasets_public/cityscapes/leftImg8bit_trainvaltest/leftImg8bit/val\n",
      "/esat/toyota/trace/deeplearning/datasets_public/cityscapes/gtFine_trainvaltest/gtFine/val\n",
      "<class '__main__.CrossEntropyLoss'>\n",
      "----- TRAINING - EPOCH 1 -----\n",
      "LEARNING RATE:  0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/students/r0777423/Documents/thesis_kontras/env/lib64/python3.7/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.689 (epoch: 1, step: 0) // Avg time/img: 0.2579 s\n",
      "loss: 1.297 (epoch: 1, step: 50) // Avg time/img: 0.2263 s\n",
      "loss: 1.195 (epoch: 1, step: 100) // Avg time/img: 0.2265 s\n",
      "loss: 1.133 (epoch: 1, step: 150) // Avg time/img: 0.2266 s\n",
      "loss: 1.1 (epoch: 1, step: 200) // Avg time/img: 0.2269 s\n",
      "loss: 1.069 (epoch: 1, step: 250) // Avg time/img: 0.2271 s\n",
      "loss: 1.052 (epoch: 1, step: 300) // Avg time/img: 0.2272 s\n",
      "loss: 1.022 (epoch: 1, step: 350) // Avg time/img: 0.2274 s\n",
      "loss: 1.006 (epoch: 1, step: 400) // Avg time/img: 0.2275 s\n",
      "loss: 0.9892 (epoch: 1, step: 450) // Avg time/img: 0.2277 s\n",
      "loss: 0.9712 (epoch: 1, step: 500) // Avg time/img: 0.2278 s\n",
      "loss: 0.953 (epoch: 1, step: 550) // Avg time/img: 0.2279 s\n",
      "loss: 0.9448 (epoch: 1, step: 600) // Avg time/img: 0.2280 s\n",
      "loss: 0.939 (epoch: 1, step: 650) // Avg time/img: 0.2281 s\n",
      "loss: 0.9244 (epoch: 1, step: 700) // Avg time/img: 0.2281 s\n",
      "loss: 0.914 (epoch: 1, step: 750) // Avg time/img: 0.2282 s\n",
      "loss: 0.9075 (epoch: 1, step: 800) // Avg time/img: 0.2284 s\n",
      "loss: 0.8997 (epoch: 1, step: 850) // Avg time/img: 0.2284 s\n",
      "loss: 0.8904 (epoch: 1, step: 900) // Avg time/img: 0.2285 s\n",
      "loss: 0.8804 (epoch: 1, step: 950) // Avg time/img: 0.2286 s\n",
      "loss: 0.871 (epoch: 1, step: 1000) // Avg time/img: 0.2287 s\n",
      "loss: 0.861 (epoch: 1, step: 1050) // Avg time/img: 0.2287 s\n",
      "loss: 0.8511 (epoch: 1, step: 1100) // Avg time/img: 0.2288 s\n",
      "loss: 0.8442 (epoch: 1, step: 1150) // Avg time/img: 0.2288 s\n",
      "loss: 0.8371 (epoch: 1, step: 1200) // Avg time/img: 0.2289 s\n",
      "loss: 0.8269 (epoch: 1, step: 1250) // Avg time/img: 0.2289 s\n",
      "loss: 0.8186 (epoch: 1, step: 1300) // Avg time/img: 0.2290 s\n",
      "loss: 0.81 (epoch: 1, step: 1350) // Avg time/img: 0.2290 s\n",
      "loss: 0.8042 (epoch: 1, step: 1400) // Avg time/img: 0.2290 s\n",
      "loss: 0.8005 (epoch: 1, step: 1450) // Avg time/img: 0.2291 s\n",
      "----- VALIDATING - EPOCH 1 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/students/r0777423/Documents/thesis_kontras/env/lib64/python3.7/site-packages/ipykernel_launcher.py:209: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/users/students/r0777423/Documents/thesis_kontras/env/lib64/python3.7/site-packages/ipykernel_launcher.py:210: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8dbdf17f4186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mepoch_loss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mtime_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "enc = True\n",
    "best_acc = 0\n",
    "\n",
    "#TODO: calculate weights by processing dataset histogram (now its being set by hand from the torch values)\n",
    "#create a loder to run all images and calculate histogram of labels, then create weight array using class balancing\n",
    "\n",
    "weight = torch.ones(NUM_CLASSES)\n",
    "if (enc):\n",
    "    weight[0] = 2.3653597831726\t\n",
    "    weight[1] = 4.4237880706787\t\n",
    "    weight[2] = 2.9691488742828\t\n",
    "    weight[3] = 5.3442072868347\t\n",
    "    weight[4] = 5.2983593940735\t\n",
    "    weight[5] = 5.2275490760803\t\n",
    "    weight[6] = 5.4394111633301\t\n",
    "    weight[7] = 5.3659925460815\t\n",
    "    weight[8] = 3.4170460700989\t\n",
    "    weight[9] = 5.2414722442627\t\n",
    "    weight[10] = 4.7376127243042\t\n",
    "    weight[11] = 5.2286224365234\t\n",
    "    weight[12] = 5.455126285553\t\n",
    "    weight[13] = 4.3019247055054\t\n",
    "    weight[14] = 5.4264230728149\t\n",
    "    weight[15] = 5.4331531524658\t\n",
    "    weight[16] = 5.433765411377\t\n",
    "    weight[17] = 5.4631009101868\t\n",
    "    weight[18] = 5.3947434425354\n",
    "else:\n",
    "    weight[0] = 2.8149201869965\t\n",
    "    weight[1] = 6.9850029945374\t\n",
    "    weight[2] = 3.7890393733978\t\n",
    "    weight[3] = 9.9428062438965\t\n",
    "    weight[4] = 9.7702074050903\t\n",
    "    weight[5] = 9.5110931396484\t\n",
    "    weight[6] = 10.311357498169\t\n",
    "    weight[7] = 10.026463508606\t\n",
    "    weight[8] = 4.6323022842407\t\n",
    "    weight[9] = 9.5608062744141\t\n",
    "    weight[10] = 7.8698215484619\t\n",
    "    weight[11] = 9.5168733596802\t\n",
    "    weight[12] = 10.373730659485\t\n",
    "    weight[13] = 6.6616044044495\t\n",
    "    weight[14] = 10.260489463806\t\n",
    "    weight[15] = 10.287888526917\t\n",
    "    weight[16] = 10.289801597595\t\n",
    "    weight[17] = 10.405355453491\t\n",
    "    weight[18] = 10.138095855713\t\n",
    "\n",
    "weight[19] = 0\n",
    "\n",
    "assert os.path.exists(args.datadir), \"Error: datadir (dataset directory) could not be loaded\"\n",
    "\n",
    "co_transform = MyCoTransform(enc, augment=True, height=args.height)#1024)\n",
    "co_transform_val = MyCoTransform(enc, augment=False, height=args.height)#1024)\n",
    "dataset_train = cityscapes(args.datadir, co_transform, 'train')\n",
    "dataset_val = cityscapes(args.datadir, co_transform_val, 'val')\n",
    "\n",
    "loader = DataLoader(dataset_train, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=True)\n",
    "loader_val = DataLoader(dataset_val, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "if args.cuda:\n",
    "    weight = weight.cuda()\n",
    "criterion = CrossEntropyLoss(weight)\n",
    "print(type(criterion))\n",
    "\n",
    "savedir = f'../save/{args.savedir}'\n",
    "\n",
    "if (enc):\n",
    "    automated_log_path = savedir + \"/automated_log_encoder.txt\"\n",
    "    modeltxtpath = savedir + \"/model_encoder.txt\"\n",
    "else:\n",
    "    automated_log_path = savedir + \"/automated_log.txt\"\n",
    "    modeltxtpath = savedir + \"/model.txt\"    \n",
    "\n",
    "if (not os.path.exists(automated_log_path)):    #dont add first line if it exists \n",
    "    with open(automated_log_path, \"a\") as myfile:\n",
    "        myfile.write(\"Epoch\\t\\tTrain-loss\\t\\tTest-loss\\t\\tTrain-IoU\\t\\tTest-IoU\\t\\tlearningRate\")\n",
    "\n",
    "with open(modeltxtpath, \"w\") as myfile:\n",
    "    myfile.write(str(model))\n",
    "\n",
    "\n",
    "#TODO: reduce memory in first gpu: https://discuss.pytorch.org/t/multi-gpu-training-memory-usage-in-balance/4163/4        #https://github.com/pytorch/pytorch/issues/1893\n",
    "\n",
    "#optimizer = Adam(model.parameters(), 5e-4, (0.9, 0.999),  eps=1e-08, weight_decay=2e-4)     ## scheduler 1\n",
    "optimizer = Adam(model.parameters(), 5e-4, (0.9, 0.999),  eps=1e-08, weight_decay=1e-4)      ## scheduler 2\n",
    "\n",
    "start_epoch = 1\n",
    "if args.resume:\n",
    "    #Must load weights, optimizer, epoch and best value. \n",
    "    if enc:\n",
    "        filenameCheckpoint = savedir + '/checkpoint_enc.pth.tar'\n",
    "    else:\n",
    "        filenameCheckpoint = savedir + '/checkpoint.pth.tar'\n",
    "\n",
    "    assert os.path.exists(filenameCheckpoint), \"Error: resume option was used but checkpoint was not found in folder\"\n",
    "    checkpoint = torch.load(filenameCheckpoint)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    print(\"=> Loaded checkpoint at epoch {})\".format(checkpoint['epoch']))\n",
    "\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5) # set up scheduler     ## scheduler 1\n",
    "lambda1 = lambda epoch: pow((1-((epoch-1)/args.num_epochs)),0.9)  ## scheduler 2\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)                             ## scheduler 2\n",
    "\n",
    "if args.visualize and args.steps_plot > 0:\n",
    "    board = Dashboard(args.port)\n",
    "\n",
    "for epoch in range(start_epoch, args.num_epochs+1):\n",
    "    print(\"----- TRAINING - EPOCH\", epoch, \"-----\")\n",
    "\n",
    "    scheduler.step(epoch)    ## scheduler 2\n",
    "\n",
    "    epoch_loss = []\n",
    "    time_train = []\n",
    "\n",
    "    doIouTrain = args.iouTrain   \n",
    "    doIouVal =  args.iouVal      \n",
    "\n",
    "    if (doIouTrain):\n",
    "        iouEvalTrain = iouEval(NUM_CLASSES)\n",
    "\n",
    "    usedLr = 0\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"LEARNING RATE: \", param_group['lr'])\n",
    "        usedLr = float(param_group['lr'])\n",
    "\n",
    "    model.train()\n",
    "    for step, (images, labels) in enumerate(loader):\n",
    "\n",
    "        start_time = time.time()\n",
    "        #print (labels.size())\n",
    "        #print (np.unique(labels.numpy()))\n",
    "        #print(\"labels: \", np.unique(labels[0].numpy()))\n",
    "        #labels = torch.ones(4, 1, 512, 1024).long()\n",
    "        if args.cuda:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        outputs = model(inputs, only_encode=enc)\n",
    "\n",
    "        #print(\"targets\", np.unique(targets[:, 0].cpu().data.numpy()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets[:, 0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.cpu().detach().numpy().item())\n",
    "        time_train.append(time.time() - start_time)\n",
    "\n",
    "        if (doIouTrain):\n",
    "            #start_time_iou = time.time()\n",
    "            iouEvalTrain.addBatch(outputs.max(1)[1].unsqueeze(1).data, targets.data)\n",
    "            #print (\"Time to add confusion matrix: \", time.time() - start_time_iou)      \n",
    "\n",
    "        #print(outputs.size())\n",
    "        if args.visualize and args.steps_plot > 0 and step % args.steps_plot == 0:\n",
    "            start_time_plot = time.time()\n",
    "            image = inputs[0].cpu().data\n",
    "            #image[0] = image[0] * .229 + .485\n",
    "            #image[1] = image[1] * .224 + .456\n",
    "            #image[2] = image[2] * .225 + .406\n",
    "            #print(\"output\", np.unique(outputs[0].cpu().max(0)[1].data.numpy()))\n",
    "            board.image(image, f'input (epoch: {epoch}, step: {step})')\n",
    "            if isinstance(outputs, list):   #merge gpu tensors\n",
    "                board.image(color_transform(outputs[0][0].cpu().max(0)[1].data.unsqueeze(0)),\n",
    "                f'output (epoch: {epoch}, step: {step})')\n",
    "            else:\n",
    "                board.image(color_transform(outputs[0].cpu().max(0)[1].data.unsqueeze(0)),\n",
    "                f'output (epoch: {epoch}, step: {step})')\n",
    "            board.image(color_transform(targets[0].cpu().data),\n",
    "                f'target (epoch: {epoch}, step: {step})')\n",
    "            print (\"Time to paint images: \", time.time() - start_time_plot)\n",
    "        if args.steps_loss > 0 and step % args.steps_loss == 0:\n",
    "            average = sum(epoch_loss) / len(epoch_loss)\n",
    "            print(f'loss: {average:0.4} (epoch: {epoch}, step: {step})', \n",
    "                    \"// Avg time/img: %.4f s\" % (sum(time_train) / len(time_train) / args.batch_size))\n",
    "\n",
    "\n",
    "    average_epoch_loss_train = sum(epoch_loss) / len(epoch_loss)\n",
    "\n",
    "    iouTrain = 0\n",
    "    if (doIouTrain):\n",
    "        iouTrain, iou_classes = iouEvalTrain.getIoU()\n",
    "        iouStr = getColorEntry(iouTrain)+'{:0.2f}'.format(iouTrain*100) + '\\033[0m'\n",
    "        print (\"EPOCH IoU on TRAIN set: \", iouStr, \"%\")  \n",
    "\n",
    "    #Validate on 500 val images after each epoch of training\n",
    "    print(\"----- VALIDATING - EPOCH\", epoch, \"-----\")\n",
    "    model.eval()\n",
    "    epoch_loss_val = []\n",
    "    time_val = []\n",
    "\n",
    "    if (doIouVal):\n",
    "        iouEvalVal = iouEval(NUM_CLASSES)\n",
    "\n",
    "    for step, (images, labels) in enumerate(loader_val):\n",
    "        start_time = time.time()\n",
    "        if args.cuda:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        inputs = Variable(images, volatile=True)    #volatile flag makes it free backward or outputs for eval\n",
    "        targets = Variable(labels, volatile=True)\n",
    "        outputs = model(inputs, only_encode=enc) \n",
    "\n",
    "        loss = criterion(outputs, targets[:, 0])\n",
    "        epoch_loss_val.append(loss.data[0])\n",
    "        time_val.append(time.time() - start_time)\n",
    "\n",
    "\n",
    "        #Add batch to calculate TP, FP and FN for iou estimation\n",
    "        if (doIouVal):\n",
    "            #start_time_iou = time.time()\n",
    "            iouEvalVal.addBatch(outputs.max(1)[1].unsqueeze(1).data, targets.data)\n",
    "            #print (\"Time to add confusion matrix: \", time.time() - start_time_iou)\n",
    "\n",
    "        if args.visualize and args.steps_plot > 0 and step % args.steps_plot == 0:\n",
    "            start_time_plot = time.time()\n",
    "            image = inputs[0].cpu().data\n",
    "            board.image(image, f'VAL input (epoch: {epoch}, step: {step})')\n",
    "            if isinstance(outputs, list):   #merge gpu tensors\n",
    "                board.image(color_transform(outputs[0][0].cpu().max(0)[1].data.unsqueeze(0)),\n",
    "                f'VAL output (epoch: {epoch}, step: {step})')\n",
    "            else:\n",
    "                board.image(color_transform(outputs[0].cpu().max(0)[1].data.unsqueeze(0)),\n",
    "                f'VAL output (epoch: {epoch}, step: {step})')\n",
    "            board.image(color_transform(targets[0].cpu().data),\n",
    "                f'VAL target (epoch: {epoch}, step: {step})')\n",
    "            print (\"Time to paint images: \", time.time() - start_time_plot)\n",
    "        if args.steps_loss > 0 and step % args.steps_loss == 0:\n",
    "            average = sum(epoch_loss_val) / len(epoch_loss_val)\n",
    "            print(f'VAL loss: {average:0.4} (epoch: {epoch}, step: {step})', \n",
    "                    \"// Avg time/img: %.4f s\" % (sum(time_val) / len(time_val) / args.batch_size))\n",
    "\n",
    "\n",
    "    average_epoch_loss_val = sum(epoch_loss_val) / len(epoch_loss_val)\n",
    "    #scheduler.step(average_epoch_loss_val, epoch)  ## scheduler 1   # update lr if needed\n",
    "\n",
    "    iouVal = 0\n",
    "    if (doIouVal):\n",
    "        iouVal, iou_classes = iouEvalVal.getIoU()\n",
    "        iouStr = getColorEntry(iouVal)+'{:0.2f}'.format(iouVal*100) + '\\033[0m'\n",
    "        print (\"EPOCH IoU on VAL set: \", iouStr, \"%\") \n",
    "\n",
    "\n",
    "    # remember best valIoU and save checkpoint\n",
    "    if iouVal == 0:\n",
    "        current_acc = -average_epoch_loss_val\n",
    "    else:\n",
    "        current_acc = iouVal \n",
    "    is_best = current_acc > best_acc\n",
    "    best_acc = max(current_acc, best_acc)\n",
    "    if enc:\n",
    "        filenameCheckpoint = savedir + '/checkpoint_enc.pth.tar'\n",
    "        filenameBest = savedir + '/model_best_enc.pth.tar'    \n",
    "    else:\n",
    "        filenameCheckpoint = savedir + '/checkpoint.pth.tar'\n",
    "        filenameBest = savedir + '/model_best.pth.tar'\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': str(model),\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, filenameCheckpoint, filenameBest)\n",
    "\n",
    "    #SAVE MODEL AFTER EPOCH\n",
    "    if (enc):\n",
    "        filename = f'{savedir}/model_encoder-{epoch:03}.pth'\n",
    "        filenamebest = f'{savedir}/model_encoder_best.pth'\n",
    "    else:\n",
    "        filename = f'{savedir}/model-{epoch:03}.pth'\n",
    "        filenamebest = f'{savedir}/model_best.pth'\n",
    "    if args.epochs_save > 0 and step > 0 and step % args.epochs_save == 0:\n",
    "        torch.save(model.state_dict(), filename)\n",
    "        print(f'save: {filename} (epoch: {epoch})')\n",
    "    if (is_best):\n",
    "        torch.save(model.state_dict(), filenamebest)\n",
    "        print(f'save: {filenamebest} (epoch: {epoch})')\n",
    "        if (not enc):\n",
    "            with open(savedir + \"/best.txt\", \"w\") as myfile:\n",
    "                myfile.write(\"Best epoch is %d, with Val-IoU= %.4f\" % (epoch, iouVal))   \n",
    "        else:\n",
    "            with open(savedir + \"/best_encoder.txt\", \"w\") as myfile:\n",
    "                myfile.write(\"Best epoch is %d, with Val-IoU= %.4f\" % (epoch, iouVal))           \n",
    "\n",
    "    #SAVE TO FILE A ROW WITH THE EPOCH RESULT (train loss, val loss, train IoU, val IoU)\n",
    "    #Epoch\t\tTrain-loss\t\tTest-loss\tTrain-IoU\tTest-IoU\t\tlearningRate\n",
    "    with open(automated_log_path, \"a\") as myfile:\n",
    "        myfile.write(\"\\n%d\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.8f\" % (epoch, average_epoch_loss_train, average_epoch_loss_val, iouTrain, iouVal, usedLr ))\n",
    "    \n",
    "#     return(model)   #return model (convenience for encoder-decoder training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(inputs.cpu().detach().numpy())\n",
    "\n",
    "# outputs = model(inputs, only_encode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- TRAINING - EPOCH 1 -----\n",
      "LEARNING RATE:  0.0005891598267371476\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "print(\"----- TRAINING - EPOCH\", epoch, \"-----\")\n",
    "\n",
    "# scheduler.step(epoch)    ## scheduler 2\n",
    "\n",
    "epoch_loss = []\n",
    "time_train = []\n",
    "\n",
    "doIouTrain = args.iouTrain   \n",
    "doIouVal =  args.iouVal      \n",
    "\n",
    "if (doIouTrain):\n",
    "    iouEvalTrain = iouEval(NUM_CLASSES)\n",
    "\n",
    "usedLr = 0\n",
    "for param_group in optimizer.param_groups:\n",
    "    print(\"LEARNING RATE: \", param_group['lr'])\n",
    "    usedLr = float(param_group['lr'])\n",
    "\n",
    "model.train()\n",
    "step =1  \n",
    "(images, labels) = next(iter(loader))\n",
    "\n",
    "start_time = time.time()\n",
    "#print (labels.size())\n",
    "#print (np.unique(labels.numpy()))\n",
    "#print(\"labels: \", np.unique(labels[0].numpy()))\n",
    "#labels = torch.ones(4, 1, 512, 1024).long()\n",
    "if args.cuda:\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "inputs = Variable(images)\n",
    "targets = Variable(labels)\n",
    "outputs = model(inputs, only_encode=enc)\n",
    "\n",
    "#print(\"targets\", np.unique(targets[:, 0].cpu().data.numpy()))\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss = criterion(outputs, targets[:, 0])\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# epoch_loss.append(loss.data[0].item())\n",
    "time_train.append(time.time() - start_time)\n",
    "\n",
    "if (doIouTrain):\n",
    "    #start_time_iou = time.time()\n",
    "    iouEvalTrain.addBatch(outputs.max(1)[1].unsqueeze(1).data, targets.data)\n",
    "    #print (\"Time to add confusion matrix: \", time.time() - start_time_iou)      \n",
    "\n",
    "#print(outputs.size())\n",
    "if args.visualize and args.steps_plot > 0 and step % args.steps_plot == 0:\n",
    "    start_time_plot = time.time()\n",
    "    image = inputs[0].cpu().data\n",
    "    #image[0] = image[0] * .229 + .485\n",
    "    #image[1] = image[1] * .224 + .456\n",
    "    #image[2] = image[2] * .225 + .406\n",
    "    #print(\"output\", np.unique(outputs[0].cpu().max(0)[1].data.numpy()))\n",
    "    board.image(image, f'input (epoch: {epoch}, step: {step})')\n",
    "    if isinstance(outputs, list):   #merge gpu tensors\n",
    "        board.image(color_transform(outputs[0][0].cpu().max(0)[1].data.unsqueeze(0)),\n",
    "        f'output (epoch: {epoch}, step: {step})')\n",
    "    else:\n",
    "        board.image(color_transform(outputs[0].cpu().max(0)[1].data.unsqueeze(0)),\n",
    "        f'output (epoch: {epoch}, step: {step})')\n",
    "    board.image(color_transform(targets[0].cpu().data),\n",
    "        f'target (epoch: {epoch}, step: {step})')\n",
    "    print (\"Time to paint images: \", time.time() - start_time_plot)\n",
    "if args.steps_loss > 0 and step % args.steps_loss == 0:\n",
    "    average = sum(epoch_loss) / len(epoch_loss)\n",
    "    print(f'loss: {average:0.4} (epoch: {epoch}, step: {step})', \n",
    "            \"// Avg time/img: %.4f s\" % (sum(time_train) / len(time_train) / args.batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(fo.cpu().detach().numpy())\n",
    "# # loss = torch.nn.functional.log_softmax(outputs, dim=1), targets\n",
    "# loss = torch.nn.NLLLoss()\n",
    "\n",
    "# loss(fo,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fo= torch.nn.functional.log_softmax(outputs[0], dim=1)\n",
    "# optimizer.zero_grad()\n",
    "# # m = torch.nn.LogSoftmax(dim=1)\n",
    "# # loss = torch.nn.NLLLoss()\n",
    "# # fo = m(outputs)\n",
    "# fl = criterion(outputs,targets[:,0])\n",
    "# fl.backward()\n",
    "# np.max(targets[:,0].cpu().detach().numpy())\n",
    "# mymin = 0\n",
    "# for step,(images, labels) in enumerate(loader):\n",
    "#     print(step)\n",
    "#     if np.min(labels.cpu().detach().numpy()) > mymin :\n",
    "#         mymin = np.max(labels.cpu().detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2D loss example (used, for example, with image inputs)\n",
    "# N, C = 5, 4\n",
    "# loss = torch.nn.NLLLoss()\n",
    "# # input is of size N x C x height x width\n",
    "# data = torch.randn(N, 16, 10, 10)\n",
    "# conv = torch.nn.Conv2d(16, C, (3, 3))\n",
    "# m = torch.nn.LogSoftmax(dim=1)\n",
    "# # each element in target has to have 0 <= value < C\n",
    "# target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n",
    "# output = loss(m(conv(data)), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.278388738632202"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.max(targets[:,0].cpu().detach().numpy())\n",
    "# np.shape(conv(data).detach().numpy())\n",
    "# criterion()\n",
    "# fl\n",
    "# from matplotlib import pyplot as plt\n",
    "# %pylab inline\n",
    "\n",
    "# plt.imshow(outputs[1,19].cpu().detach().numpy(),cmap='gray')\n",
    "# plt.show\n",
    "# loss.cpu().detach().numpy()\n",
    "# loss.backward()\n",
    "loss.cpu().detach().numpy().item()\n",
    "# a.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
